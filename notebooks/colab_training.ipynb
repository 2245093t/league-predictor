{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2868b398",
   "metadata": {},
   "source": [
    "# âš½ Football League Predictor - Training Notebook\n",
    "\n",
    "Google Colab GPUç’°å¢ƒã§ã®æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "## ğŸ¯ ç›®çš„\n",
    "- è¤‡æ•°ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ã§çµ±åˆå­¦ç¿’\n",
    "- ã‚ªãƒƒã‚ºã«ä¾å­˜ã—ãªã„PPGãƒ»xGãƒ™ãƒ¼ã‚¹ã®äºˆæ¸¬\n",
    "- ç¶™ç¶šå­¦ç¿’ãƒ»ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾å¿œ\n",
    "- PyTorchãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808a812",
   "metadata": {},
   "source": [
    "## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install pytorch-lightning\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "!pip install pyyaml hydra-core\n",
    "\n",
    "# GPUç¢ºèª\n",
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveãƒã‚¦ãƒ³ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ï¼‰\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šï¼ˆçµ±ä¸€ï¼‰\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/league-predictor'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"ğŸ“ Google Driveãƒã‚¦ãƒ³ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ac675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHubãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "if not os.path.exists('league-predictor'):\n",
    "    !git clone https://github.com/2245093t/league-predictor.git\n",
    "    print(\"âœ… GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã—ãŸ\")\n",
    "else:\n",
    "    print(\"âœ… GitHubãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™\")\n",
    "    \n",
    "# league-predictorãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•\n",
    "os.chdir('league-predictor')\n",
    "print(f\"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n",
    "\n",
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª\n",
    "print(\"\\nğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\nğŸ“ srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹:\")\n",
    "if os.path.exists('src'):\n",
    "    !ls -la src/\n",
    "    print(\"\\nğŸ“ src/training ã®å†…å®¹:\")\n",
    "    if os.path.exists('src/training'):\n",
    "        !ls -la src/training/\n",
    "else:\n",
    "    print(\"âŒ srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901ff0a",
   "metadata": {},
   "source": [
    "## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
    "\n",
    "Google Driveä¸Šã®`stats-csv`ãƒ•ã‚©ãƒ«ãƒ€ã«ç›´æ¥ä¿å­˜ã•ã‚ŒãŸãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ç¢ºèªï¼ˆGoogle Driveçµ±åˆç®¡ç†ï¼‰\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
    "CSV_DIR = \"/content/drive/MyDrive/league-predictor/stats-csv\"\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "# æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª\n",
    "existing_files = glob.glob(os.path.join(CSV_DIR, \"*.csv\"))\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š GOOGLE DRIVE ãƒ‡ãƒ¼ã‚¿ç¢ºèª\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {CSV_DIR}\")\n",
    "print(f\"ğŸ“„ æ¤œå‡ºã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«: {len(existing_files)}å€‹\")\n",
    "\n",
    "if existing_files:\n",
    "    print(\"\\nğŸ† ãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:\")\n",
    "    total_matches = 0\n",
    "    \n",
    "    for i, file in enumerate(existing_files, 1):\n",
    "        filename = os.path.basename(file)\n",
    "        df = pd.read_csv(file)\n",
    "        file_size = os.path.getsize(file) / (1024 * 1024)  # MB\n",
    "        total_matches += len(df)\n",
    "        \n",
    "        print(f\"  {i}. {filename}\")\n",
    "        print(f\"     è©¦åˆæ•°: {len(df):,}\")\n",
    "        print(f\"     ã‚µã‚¤ã‚º: {file_size:.1f}MB\")\n",
    "        print(f\"     ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ç·è¨ˆ:\")\n",
    "    print(f\"  ç·è©¦åˆæ•°: {total_matches:,}\")\n",
    "    print(f\"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(existing_files)}\")\n",
    "    \n",
    "    print(\"\\nâœ… å…¨ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒçµ±åˆæº–å‚™å®Œäº†ï¼\")\n",
    "    print(\"ğŸŒ å„ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒå¯¾ç­‰ã«æ‰±ã‚ã‚Œã¾ã™\")\n",
    "else:\n",
    "    print(\"\\nâŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"ğŸ“ æ–°ã—ã„ãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã«ã¯:\")\n",
    "    print(\"   1. Google Driveã§ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ã‚¯ã‚»ã‚¹\")\n",
    "    print(f\"   2. {CSV_DIR}\")\n",
    "    print(\"   3. ãƒªãƒ¼ã‚°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
    "    print(\"   4. ã“ã®ã‚»ãƒ«ã‚’å†å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ æ–°ã—ã„ãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ãŸã„å ´åˆ:\")\n",
    "print(f\"   Google Driveã® {CSV_DIR} ãƒ•ã‚©ãƒ«ãƒ€ã«\")\n",
    "print(\"   CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆãƒ‡ãƒ¼ã‚¿æ¦‚è¦ç¢ºèª\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# srcãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’è¿½åŠ \n",
    "sys.path.append('src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/src')\n",
    "\n",
    "from training.data_loader import UnifiedDataLoader\n",
    "\n",
    "def analyze_unified_data():\n",
    "    \"\"\"çµ±åˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’åˆ†æ\"\"\"\n",
    "    \n",
    "    config = {'batch_size': 64, 'feature_dim': 11}\n",
    "    loader = UnifiedDataLoader(config)\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±å–å¾—\n",
    "    stats = loader.get_league_statistics(CSV_DIR)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸŒ UNIFIED LEAGUE DATA ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"ğŸ“Š å…¨ä½“çµ±è¨ˆ:\")\n",
    "    print(f\"  ç·è©¦åˆæ•°: {stats['total_matches']:,}\")\n",
    "    print(f\"  ç·ãƒãƒ¼ãƒ æ•°: {stats['total_teams']:,}\")\n",
    "    \n",
    "    print(f\"\\nğŸ† ãƒªãƒ¼ã‚°åˆ¥åˆ†å¸ƒ:\")\n",
    "    for league, count in stats['league_distribution'].items():\n",
    "        percentage = (count / stats['total_matches']) * 100\n",
    "        print(f\"  {league}: {count:,}è©¦åˆ ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nâš½ ãƒªãƒ¼ã‚°åˆ¥ãƒãƒ¼ãƒ æ•°:\")\n",
    "    for league, count in stats['teams_per_league'].items():\n",
    "        print(f\"  {league}: {count}ãƒãƒ¼ãƒ \")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "    csv_files = glob.glob(os.path.join(CSV_DIR, \"*.csv\"))\n",
    "    print(f\"\\nğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°:\")\n",
    "    \n",
    "    total_size = 0\n",
    "    for csv_file in csv_files:\n",
    "        filename = os.path.basename(csv_file)\n",
    "        file_size = os.path.getsize(csv_file) / (1024 * 1024)  # MB\n",
    "        total_size += file_size\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"  {filename}\")\n",
    "        print(f\"    ã‚µã‚¤ã‚º: {file_size:.1f}MB\")\n",
    "        print(f\"    è©¦åˆæ•°: {len(df):,}\")\n",
    "        print(f\"    ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size:.1f}MB\")\n",
    "    print(\"\\nâœ… å…¨ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒçµ±åˆæº–å‚™å®Œäº†ï¼\")\n",
    "\n",
    "analyze_unified_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51b542",
   "metadata": {},
   "source": [
    "## âš™ï¸ å­¦ç¿’è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea673e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆå­¦ç¿’è¨­å®š\n",
    "TRAINING_CONFIG = {\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
    "    'num_teams': 500,        # å¤šãƒªãƒ¼ã‚°çµ±åˆã®ãŸã‚å¤§å¹…å¢—åŠ \n",
    "    'embedding_dim': 64,     # ãƒãƒ¼ãƒ åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒå¢—åŠ \n",
    "    'hidden_dim': 512,       # éš ã‚Œå±¤æ¬¡å…ƒå¢—åŠ \n",
    "    'dropout': 0.3,          # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡\n",
    "    \n",
    "    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 128,       # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ãƒãƒƒãƒã‚µã‚¤ã‚ºå¢—åŠ \n",
    "    'epochs': 150,           # ã‚¨ãƒãƒƒã‚¯æ•°èª¿æ•´\n",
    "    \n",
    "    # æå¤±é–¢æ•°é‡ã¿\n",
    "    'goal_loss_weight': 1.0,\n",
    "    'result_loss_weight': 2.0,\n",
    "    \n",
    "    # ãƒ‡ãƒã‚¤ã‚¹\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Google Driveè¨­å®š\n",
    "DRIVE_CONFIG = {\n",
    "    'csv_dir': CSV_DIR,\n",
    "    'model_save_dir': '/content/drive/MyDrive/league-predictor/models',\n",
    "    'encoder_save_path': '/content/drive/MyDrive/league-predictor/models/team_encoder.json'\n",
    "}\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "os.makedirs(DRIVE_CONFIG['model_save_dir'], exist_ok=True)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“‹ çµ±åˆå­¦ç¿’è¨­å®š\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“ CSVãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DRIVE_CONFIG['csv_dir']}\")\n",
    "print(f\"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DRIVE_CONFIG['model_save_dir']}\")\n",
    "print(f\"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {TRAINING_CONFIG['device']}\")\n",
    "print(f\"ğŸ§  æœ€å¤§ãƒãƒ¼ãƒ æ•°: {TRAINING_CONFIG['num_teams']}\")\n",
    "print(f\"ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"ğŸ”„ ã‚¨ãƒãƒƒã‚¯æ•°: {TRAINING_CONFIG['epochs']}\")\n",
    "print()\n",
    "print(\"âœ… å…¨ãƒªãƒ¼ã‚°ãŒå¯¾ç­‰ã«æ‰±ã‚ã‚Œã‚‹çµ±åˆå­¦ç¿’ã®æº–å‚™å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20a1ad",
   "metadata": {},
   "source": [
    "## ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆå­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# srcãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’è¿½åŠ ï¼ˆè¤‡æ•°ã®å¯èƒ½æ€§ã«å¯¾å¿œï¼‰\n",
    "sys.path.append('src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/league-predictor/src')\n",
    "\n",
    "# ç¾åœ¨ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python path: {sys.path[-3:]}\")\n",
    "\n",
    "try:\n",
    "    # æ­£ã—ã„ã‚¯ãƒ©ã‚¹åã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "    from training.data_loader import UnifiedDataLoader\n",
    "    from training.train_model import FootballTrainer\n",
    "    from training.model_architecture import FootballMatchPredictor\n",
    "    \n",
    "    print(\"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n",
    "    print(\"ğŸŒ å…¨ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒå¯¾ç­‰ã«æ‰±ã‚ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"ğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¾ã™:\")\n",
    "    \n",
    "    # srcãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ç¢ºèª\n",
    "    if os.path.exists('src'):\n",
    "        print(\"src/ ãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹:\")\n",
    "        for root, dirs, files in os.walk('src'):\n",
    "            level = root.replace('src', '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files:\n",
    "                if file.endswith('.py'):\n",
    "                    print(f\"{subindent}{file}\")\n",
    "    else:\n",
    "        print(\"src/ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    # å…·ä½“çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ç¢ºèª\n",
    "    data_loader_path = 'src/training/data_loader.py'\n",
    "    if os.path.exists(data_loader_path):\n",
    "        print(f\"\\nğŸ“„ {data_loader_path} ã®å†…å®¹ã‚’ç¢ºèª:\")\n",
    "        with open(data_loader_path, 'r') as f:\n",
    "            lines = f.readlines()[:20]  # æœ€åˆã®20è¡Œã‚’è¡¨ç¤º\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                if 'class' in line or 'def' in line:\n",
    "                    print(f\"  {i}: {line.strip()}\")\n",
    "    \n",
    "    # ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ\n",
    "    print(\"\\nğŸ”§ ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ:\")\n",
    "    try:\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\"data_loader\", data_loader_path)\n",
    "        data_loader_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(data_loader_module)\n",
    "        \n",
    "        # åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚’ç¢ºèª\n",
    "        classes = [name for name in dir(data_loader_module) if name[0].isupper()]\n",
    "        print(f\"  åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹: {classes}\")\n",
    "        \n",
    "        # UnifiedDataLoaderã‚¯ãƒ©ã‚¹ã‚’å–å¾—\n",
    "        if hasattr(data_loader_module, 'UnifiedDataLoader'):\n",
    "            UnifiedDataLoader = getattr(data_loader_module, 'UnifiedDataLoader')\n",
    "            print(\"  âœ… UnifiedDataLoader ã‚’ç›´æ¥èª­ã¿è¾¼ã¿æˆåŠŸ\")\n",
    "        else:\n",
    "            print(\"  âŒ UnifiedDataLoader ã‚¯ãƒ©ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            \n",
    "    except Exception as direct_error:\n",
    "        print(f\"  âŒ ç›´æ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {direct_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª\n",
    "pretrained_path = 'models/saved/best_model.pth'\n",
    "\n",
    "if os.path.exists(pretrained_path):\n",
    "    print(f\"äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {pretrained_path}\")\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ç¢ºèª\n",
    "    checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "    if 'metadata' in checkpoint:\n",
    "        metadata = checkpoint['metadata']\n",
    "        print(f\"å‰å›ã®å­¦ç¿’ã‚¨ãƒãƒƒã‚¯: {metadata.get('epoch', 'Unknown')}\")\n",
    "        print(f\"æ¤œè¨¼æå¤±: {metadata.get('val_loss', 'Unknown')}\")\n",
    "        print(f\"ç²¾åº¦: {metadata.get('accuracy', 'Unknown')}\")\n",
    "        \n",
    "    use_pretrained = True\n",
    "else:\n",
    "    print(\"äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚\")\n",
    "    pretrained_path = None\n",
    "    use_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆå­¦ç¿’é–‹å§‹\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸŒ UNIFIED MULTI-LEAGUE TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# å¿…è¦ãªã‚¯ãƒ©ã‚¹ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "required_classes = ['UnifiedDataLoader', 'FootballTrainer', 'FootballMatchPredictor']\n",
    "missing_classes = []\n",
    "\n",
    "for class_name in required_classes:\n",
    "    if class_name not in globals():\n",
    "        missing_classes.append(class_name)\n",
    "\n",
    "if missing_classes:\n",
    "    print(f\"âŒ æœªã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ã‚¯ãƒ©ã‚¹: {missing_classes}\")\n",
    "    print(\"ğŸ”§ ç·Šæ€¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™...\")\n",
    "    \n",
    "    # ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ\n",
    "    try:\n",
    "        import sys\n",
    "        import importlib.util\n",
    "        \n",
    "        # data_loader.pyã‹ã‚‰ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "        data_loader_path = 'src/training/data_loader.py'\n",
    "        spec = importlib.util.spec_from_file_location(\"data_loader\", data_loader_path)\n",
    "        data_loader_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(data_loader_module)\n",
    "        UnifiedDataLoader = getattr(data_loader_module, 'UnifiedDataLoader')\n",
    "        \n",
    "        # train_model.pyã‹ã‚‰ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "        train_model_path = 'src/training/train_model.py'\n",
    "        spec = importlib.util.spec_from_file_location(\"train_model\", train_model_path)\n",
    "        train_model_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(train_model_module)\n",
    "        FootballTrainer = getattr(train_model_module, 'FootballTrainer')\n",
    "        \n",
    "        # model_architecture.pyã‹ã‚‰ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "        model_arch_path = 'src/training/model_architecture.py'\n",
    "        spec = importlib.util.spec_from_file_location(\"model_architecture\", model_arch_path)\n",
    "        model_arch_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(model_arch_module)\n",
    "        FootballMatchPredictor = getattr(model_arch_module, 'FootballMatchPredictor')\n",
    "        \n",
    "        print(\"âœ… ç·Šæ€¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ!\")\n",
    "        \n",
    "    except Exception as import_error:\n",
    "        print(f\"âŒ ç·Šæ€¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {import_error}\")\n",
    "        print(\"ç¬¬11ã‚»ãƒ«ï¼ˆçµ±åˆå­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "        raise ImportError(\"å¿…è¦ãªã‚¯ãƒ©ã‚¹ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "\n",
    "# çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–\n",
    "data_loader = UnifiedDataLoader(TRAINING_CONFIG)\n",
    "\n",
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰\n",
    "encoder_path = DRIVE_CONFIG['encoder_save_path']\n",
    "if os.path.exists(encoder_path):\n",
    "    data_loader.load_team_encoder(encoder_path)\n",
    "    print(f\"âœ… æ—¢å­˜ã®ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’èª­ã¿è¾¼ã¿: {len(data_loader.team_encoder)}ãƒãƒ¼ãƒ \")\n",
    "\n",
    "# çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "print(f\"ğŸ“Š Google Driveã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {DRIVE_CONFIG['csv_dir']}\")\n",
    "train_dataloader = data_loader.load_from_drive(DRIVE_CONFIG['csv_dir'])\n",
    "\n",
    "# ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ä¿å­˜\n",
    "data_loader.save_team_encoder(DRIVE_CONFIG['encoder_save_path'])\n",
    "print(f\"ğŸ’¾ ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ä¿å­˜: {DRIVE_CONFIG['encoder_save_path']}\")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–\n",
    "trainer = FootballTrainer(TRAINING_CONFIG)\n",
    "\n",
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰\n",
    "pretrained_model_path = os.path.join(DRIVE_CONFIG['model_save_dir'], 'best_model.pth')\n",
    "if os.path.exists(pretrained_model_path) and use_pretrained:\n",
    "    trainer.initialize_model(pretrained_model_path)\n",
    "    print(f\"ğŸ”„ ç¶™ç¶šå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰: {pretrained_model_path}\")\n",
    "else:\n",
    "    trainer.initialize_model(None)\n",
    "    print(\"ğŸ†• æ–°è¦å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰\")\n",
    "\n",
    "# å­¦ç¿’å®Ÿè¡Œ\n",
    "print(\"\\nğŸš€ çµ±åˆå­¦ç¿’é–‹å§‹...\")\n",
    "trainer.train_with_unified_data(\n",
    "    train_dataloader=train_dataloader,\n",
    "    validation_split=0.2,\n",
    "    save_path=DRIVE_CONFIG['model_save_dir'],\n",
    "    checkpoint_interval=25\n",
    ")\n",
    "\n",
    "print(\"âœ… çµ±åˆå­¦ç¿’å®Œäº†ï¼\")\n",
    "print(\"ğŸ† å…¨ãƒªãƒ¼ã‚°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeee6c",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # æå¤±\n",
    "    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['epoch'], history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # ã‚´ãƒ¼ãƒ«äºˆæ¸¬æå¤±\n",
    "    axes[0, 1].plot(history['epoch'], history['goal_loss'], label='Goal Loss', color='orange')\n",
    "    axes[0, 1].set_title('Goal Prediction Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('MSE Loss')\n",
    "    \n",
    "    # çµæœäºˆæ¸¬æå¤±\n",
    "    axes[1, 0].plot(history['epoch'], history['result_loss'], label='Result Loss', color='green')\n",
    "    axes[1, 0].set_title('Result Prediction Loss')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('CrossEntropy Loss')\n",
    "    \n",
    "    # ç²¾åº¦\n",
    "    axes[1, 1].plot(history['epoch'], history['accuracy'], label='Accuracy', color='red')\n",
    "    axes[1, 1].set_title('Classification Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# å­¦ç¿’å±¥æ­´ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "if trainer.train_history['epoch']:\n",
    "    plot_training_history(trainer.train_history)\n",
    "else:\n",
    "    print(\"å­¦ç¿’å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆäºˆæ¸¬\n",
    "def test_model_prediction():\n",
    "    # Google Driveä¸Šã®æ­£ã—ã„ãƒ‘ã‚¹ã‚’ä½¿ç”¨\n",
    "    model_path = os.path.join(DRIVE_CONFIG['model_save_dir'], 'best_model.pth')\n",
    "    encoder_path = DRIVE_CONFIG['encoder_save_path']\n",
    "    \n",
    "    # ãƒ‘ã‚¹ç¢ºèª\n",
    "    print(f\"ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}\")\n",
    "    print(f\"ğŸ” ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ‘ã‚¹: {encoder_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}\")\n",
    "        print(\"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "        model_dir = DRIVE_CONFIG['model_save_dir']\n",
    "        if os.path.exists(model_dir):\n",
    "            for file in os.listdir(model_dir):\n",
    "                if file.endswith('.pth'):\n",
    "                    print(f\"  {file}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(encoder_path):\n",
    "        print(f\"âŒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {encoder_path}\")\n",
    "        return\n",
    "    \n",
    "    # æœ€æ–°ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿\n",
    "    model = FootballMatchPredictor.load_model(\n",
    "        model_path, \n",
    "        device=TRAINING_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿\n",
    "    import json\n",
    "    with open(encoder_path, 'r', encoding='utf-8') as f:\n",
    "        team_encoder = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\")\n",
    "    print(f\"âœ… ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿å®Œäº†: {len(team_encoder)}ãƒãƒ¼ãƒ \")\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬\n",
    "    sample_matches = [\n",
    "        {\n",
    "            'home_team': 'Manchester City',\n",
    "            'away_team': 'Liverpool',\n",
    "            'features': np.array([2.8, 2.7, 2.9, 2.6, 2.2, 2.0, 1.0, 1.1, 0.5, 0.3, 0.1])\n",
    "        },\n",
    "        {\n",
    "            'home_team': 'Arsenal', \n",
    "            'away_team': 'Chelsea',\n",
    "            'features': np.array([2.1, 2.0, 2.2, 1.9, 1.8, 1.7, 1.2, 1.3, 0.6, 0.3, -0.1])\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ”® ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬çµæœ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for match in sample_matches:\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        \n",
    "        if home_team in team_encoder and away_team in team_encoder:\n",
    "            home_id = team_encoder[home_team]\n",
    "            away_id = team_encoder[away_team]\n",
    "            \n",
    "            prediction = model.predict_match(home_id, away_id, match['features'])\n",
    "            \n",
    "            print(f\"\\n{home_team} vs {away_team}\")\n",
    "            print(f\"äºˆæ¸¬ã‚¹ã‚³ã‚¢: {prediction['home_goals']:.1f} - {prediction['away_goals']:.1f}\")\n",
    "            print(f\"å‹åˆ©ç¢ºç‡: ãƒ›ãƒ¼ãƒ  {prediction['home_win_prob']:.1%}, \"\n",
    "                  f\"ãƒ‰ãƒ­ãƒ¼ {prediction['draw_prob']:.1%}, \"\n",
    "                  f\"ã‚¢ã‚¦ã‚§ã‚¤ {prediction['away_win_prob']:.1%}\")\n",
    "            print(f\"äºˆæ¸¬çµæœ: {prediction['predicted_result']}\")\n",
    "        else:\n",
    "            print(f\"âŒ ãƒãƒ¼ãƒ  {home_team} ã¾ãŸã¯ {away_team} ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            print(f\"  åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒ ä¾‹: {list(team_encoder.keys())[:10]}...\")\n",
    "\n",
    "test_model_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e64c9",
   "metadata": {},
   "source": [
    "## ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’æ—¥ä»˜ä»˜ãã§ä¿å­˜\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_model_name = f'football_predictor_{timestamp}.pth'\n",
    "final_model_path = os.path.join(DRIVE_CONFIG['model_save_dir'], final_model_name)\n",
    "\n",
    "# æœ€æ–°ã®ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
    "best_model_path = os.path.join(DRIVE_CONFIG['model_save_dir'], 'best_model.pth')\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    !cp \"{best_model_path}\" \"{final_model_path}\"\n",
    "    print(f\"âœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {final_model_path}\")\n",
    "else:\n",
    "    print(f\"âŒ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {best_model_path}\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n",
    "print(f\"\\nğŸ“ ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« ({DRIVE_CONFIG['model_save_dir']}):\")\n",
    "if os.path.exists(DRIVE_CONFIG['model_save_dir']):\n",
    "    !ls -lh \"{DRIVE_CONFIG['model_save_dir']}\"/*.pth\n",
    "else:\n",
    "    print(\"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "from google.colab import files\n",
    "\n",
    "# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆGoogle Driveä¸Šã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰\n",
    "download_files = [\n",
    "    os.path.join(DRIVE_CONFIG['model_save_dir'], 'best_model.pth'),\n",
    "    DRIVE_CONFIG['encoder_save_path'],\n",
    "    final_model_path  # å‰ã®ã‚»ãƒ«ã§å®šç¾©ã•ã‚ŒãŸå¤‰æ•°\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹...\")\n",
    "print(f\"ğŸ“ å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DRIVE_CONFIG['model_save_dir']}\")\n",
    "\n",
    "for file_path in download_files:\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            files.download(file_path)\n",
    "            filename = os.path.basename(file_path)\n",
    "            print(f\"âœ… {filename} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {os.path.basename(file_path)} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    else:\n",
    "        print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {os.path.basename(file_path)}\")\n",
    "\n",
    "print(\"\\n\udccb ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "print(\"1. best_model.pth - æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«\")\n",
    "print(\"2. team_encoder.json - ãƒãƒ¼ãƒ åã¨IDã®ãƒãƒƒãƒ”ãƒ³ã‚°\")\n",
    "print(\"3. football_predictor_[timestamp].pth - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\")\n",
    "print(\"\\nğŸ’¡ ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã® models/saved/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b612f",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "1. **ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®äºˆæ¸¬**: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ä½¿ç”¨\n",
    "2. **æ–°ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: æ–°ã—ã„ãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚ŒãŸã‚‰ç¶™ç¶šå­¦ç¿’\n",
    "3. **äºˆæ¸¬ç²¾åº¦ã®è©•ä¾¡**: å®Ÿéš›ã®è©¦åˆçµæœã¨æ¯”è¼ƒã—ã¦ç²¾åº¦ã‚’æ¤œè¨¼\n",
    "4. **è‡ªå‹•åŒ–**: å®šæœŸçš„ãªå­¦ç¿’ã¨ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã®è‡ªå‹•åŒ–\n",
    "\n",
    "### ç¶™ç¶šå­¦ç¿’ã®å®Ÿè¡Œæ–¹æ³•\n",
    "```python\n",
    "# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ å¾Œã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å†å®Ÿè¡Œ\n",
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œã•ã‚Œã¾ã™\n",
    "```\n",
    "\n",
    "### ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ä½¿ç”¨æ–¹æ³•\n",
    "```python\n",
    "from src.prediction.predict_matches import predict_weekly_matches\n",
    "\n",
    "# é€±æ¬¡äºˆæ¸¬ã®å®Ÿè¡Œ\n",
    "predictions = predict_weekly_matches('data/fixtures/current_season.csv')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
