{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2868b398",
   "metadata": {},
   "source": [
    "# ⚽ Football League Predictor - Training Notebook\n",
    "\n",
    "Google Colab GPU環境での深層学習モデル学習用ノートブック\n",
    "\n",
    "## 🎯 目的\n",
    "- 複数リーグのデータで統合学習\n",
    "- オッズに依存しないPPG・xGベースの予測\n",
    "- 継続学習・ファインチューニング対応\n",
    "- PyTorchモデルの保存・読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808a812",
   "metadata": {},
   "source": [
    "## 🚀 セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab環境のセットアップ\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install pytorch-lightning\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "!pip install pyyaml hydra-core\n",
    "\n",
    "# GPU確認\n",
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveマウント（データとモデル保存用）\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# プロジェクトディレクトリ設定（統一）\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/league-predictor'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"📁 Google Driveマウント完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ac675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHubリポジトリクローン（初回のみ）\n",
    "if not os.path.exists('league-predictor'):\n",
    "    !git clone https://github.com/2245093t/league-predictor.git\n",
    "    print(\"✅ GitHubリポジトリをクローンしました\")\n",
    "else:\n",
    "    print(\"✅ GitHubリポジトリは既に存在します\")\n",
    "    \n",
    "# league-predictorディレクトリに移動\n",
    "os.chdir('league-predictor')\n",
    "print(f\"作業ディレクトリ: {os.getcwd()}\")\n",
    "\n",
    "# ディレクトリ構造確認\n",
    "print(\"\\n📁 プロジェクト構造:\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\n📁 srcディレクトリの内容:\")\n",
    "if os.path.exists('src'):\n",
    "    !ls -la src/\n",
    "    print(\"\\n📁 src/training の内容:\")\n",
    "    if os.path.exists('src/training'):\n",
    "        !ls -la src/training/\n",
    "else:\n",
    "    print(\"❌ srcディレクトリが見つかりません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901ff0a",
   "metadata": {},
   "source": [
    "## 📊 データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データアップロード（Google Drive統合管理）\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# CSVファイルディレクトリの設定\n",
    "CSV_DIR = \"/content/drive/MyDrive/league-predictor/stats-csv\"\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "# 既存のCSVファイル確認\n",
    "existing_files = glob.glob(os.path.join(CSV_DIR, \"*.csv\"))\n",
    "print(f\"既存のCSVファイル: {len(existing_files)}個\")\n",
    "for file in existing_files:\n",
    "    filename = os.path.basename(file)\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"  {filename}: {len(df)}試合\")\n",
    "\n",
    "# 新しいCSVファイルをアップロード\n",
    "print(\"\\n新しいリーグデータファイルをアップロードしてください\")\n",
    "print(\"（複数のリーグのCSVファイルを一度にアップロード可能）\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# アップロードされたファイルをCSVディレクトリに移動\n",
    "for filename in uploaded.keys():\n",
    "    destination = os.path.join(CSV_DIR, filename)\n",
    "    !mv \"{filename}\" \"{destination}\"\n",
    "    print(f\"  {filename} → {destination}\")\n",
    "        \n",
    "print(f\"\\nデータアップロード完了: {CSV_DIR}\")\n",
    "print(\"全リーグのデータが統合され、対等に扱われます\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統合データ概要確認\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# srcフォルダのパスを追加\n",
    "sys.path.append('src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/src')\n",
    "\n",
    "from training.data_loader import UnifiedDataLoader\n",
    "\n",
    "def analyze_unified_data():\n",
    "    \"\"\"統合されたデータの概要を分析\"\"\"\n",
    "    \n",
    "    config = {'batch_size': 64, 'feature_dim': 11}\n",
    "    loader = UnifiedDataLoader(config)\n",
    "    \n",
    "    # 統計情報取得\n",
    "    stats = loader.get_league_statistics(CSV_DIR)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"🌍 UNIFIED LEAGUE DATA ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"📊 全体統計:\")\n",
    "    print(f\"  総試合数: {stats['total_matches']:,}\")\n",
    "    print(f\"  総チーム数: {stats['total_teams']:,}\")\n",
    "    \n",
    "    print(f\"\\n🏆 リーグ別分布:\")\n",
    "    for league, count in stats['league_distribution'].items():\n",
    "        percentage = (count / stats['total_matches']) * 100\n",
    "        print(f\"  {league}: {count:,}試合 ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n⚽ リーグ別チーム数:\")\n",
    "    for league, count in stats['teams_per_league'].items():\n",
    "        print(f\"  {league}: {count}チーム\")\n",
    "    \n",
    "    # データ品質チェック\n",
    "    csv_files = glob.glob(os.path.join(CSV_DIR, \"*.csv\"))\n",
    "    print(f\"\\n📁 CSVファイル詳細:\")\n",
    "    \n",
    "    total_size = 0\n",
    "    for csv_file in csv_files:\n",
    "        filename = os.path.basename(csv_file)\n",
    "        file_size = os.path.getsize(csv_file) / (1024 * 1024)  # MB\n",
    "        total_size += file_size\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"  {filename}\")\n",
    "        print(f\"    サイズ: {file_size:.1f}MB\")\n",
    "        print(f\"    試合数: {len(df):,}\")\n",
    "        print(f\"    カラム数: {len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\n💾 総データサイズ: {total_size:.1f}MB\")\n",
    "    print(\"\\n✅ 全リーグのデータが統合準備完了！\")\n",
    "\n",
    "analyze_unified_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51b542",
   "metadata": {},
   "source": [
    "## ⚙️ 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea673e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統合学習設定\n",
    "TRAINING_CONFIG = {\n",
    "    # モデルアーキテクチャ\n",
    "    'num_teams': 500,        # 多リーグ統合のため大幅増加\n",
    "    'embedding_dim': 64,     # チーム埋め込み次元増加\n",
    "    'hidden_dim': 512,       # 隠れ層次元増加\n",
    "    'dropout': 0.3,          # ドロップアウト率\n",
    "    \n",
    "    # 学習パラメータ\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 128,       # 大量データのためバッチサイズ増加\n",
    "    'epochs': 150,           # エポック数調整\n",
    "    \n",
    "    # 損失関数重み\n",
    "    'goal_loss_weight': 1.0,\n",
    "    'result_loss_weight': 2.0,\n",
    "    \n",
    "    # デバイス\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Google Drive設定\n",
    "DRIVE_CONFIG = {\n",
    "    'csv_dir': CSV_DIR,\n",
    "    'model_save_dir': '/content/drive/MyDrive/league-predictor/models',\n",
    "    'encoder_save_path': '/content/drive/MyDrive/league-predictor/models/team_encoder.json'\n",
    "}\n",
    "\n",
    "# モデル保存ディレクトリ作成\n",
    "os.makedirs(DRIVE_CONFIG['model_save_dir'], exist_ok=True)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"📋 統合学習設定\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📍 CSVデータディレクトリ: {DRIVE_CONFIG['csv_dir']}\")\n",
    "print(f\"💾 モデル保存ディレクトリ: {DRIVE_CONFIG['model_save_dir']}\")\n",
    "print(f\"🔧 使用デバイス: {TRAINING_CONFIG['device']}\")\n",
    "print(f\"🧠 最大チーム数: {TRAINING_CONFIG['num_teams']}\")\n",
    "print(f\"📦 バッチサイズ: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"🔄 エポック数: {TRAINING_CONFIG['epochs']}\")\n",
    "print()\n",
    "print(\"✅ 全リーグが対等に扱われる統合学習の準備完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20a1ad",
   "metadata": {},
   "source": [
    "## 🧠 モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統合学習モジュールのインポート\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# srcフォルダのパスを追加（複数の可能性に対応）\n",
    "sys.path.append('src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/league-predictor/src')\n",
    "\n",
    "# 現在の作業ディレクトリを確認\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python path: {sys.path[-3:]}\")\n",
    "\n",
    "try:\n",
    "    # 正しいクラス名でインポート\n",
    "    from training.data_loader import UnifiedDataLoader\n",
    "    from training.train_model import FootballTrainer\n",
    "    from training.model_architecture import FootballMatchPredictor\n",
    "    \n",
    "    print(\"✅ 統合データローダーのインポート完了\")\n",
    "    print(\"🌍 全リーグのデータが対等に扱われるシステムです\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ インポートエラー: {e}\")\n",
    "    print(\"📁 利用可能なファイルを確認します:\")\n",
    "    \n",
    "    # srcフォルダの内容確認\n",
    "    if os.path.exists('src'):\n",
    "        print(\"src/ フォルダの内容:\")\n",
    "        for root, dirs, files in os.walk('src'):\n",
    "            level = root.replace('src', '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files:\n",
    "                if file.endswith('.py'):\n",
    "                    print(f\"{subindent}{file}\")\n",
    "    else:\n",
    "        print(\"src/ フォルダが見つかりません\")\n",
    "    \n",
    "    # 具体的なファイル内容確認\n",
    "    data_loader_path = 'src/training/data_loader.py'\n",
    "    if os.path.exists(data_loader_path):\n",
    "        print(f\"\\n📄 {data_loader_path} の内容を確認:\")\n",
    "        with open(data_loader_path, 'r') as f:\n",
    "            lines = f.readlines()[:20]  # 最初の20行を表示\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                if 'class' in line or 'def' in line:\n",
    "                    print(f\"  {i}: {line.strip()}\")\n",
    "    \n",
    "    # 直接インポートを試行\n",
    "    print(\"\\n🔧 直接インポートを試行:\")\n",
    "    try:\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\"data_loader\", data_loader_path)\n",
    "        data_loader_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(data_loader_module)\n",
    "        \n",
    "        # 利用可能なクラスを確認\n",
    "        classes = [name for name in dir(data_loader_module) if name[0].isupper()]\n",
    "        print(f\"  利用可能なクラス: {classes}\")\n",
    "        \n",
    "        # UnifiedDataLoaderクラスを取得\n",
    "        if hasattr(data_loader_module, 'UnifiedDataLoader'):\n",
    "            UnifiedDataLoader = getattr(data_loader_module, 'UnifiedDataLoader')\n",
    "            print(\"  ✅ UnifiedDataLoader を直接読み込み成功\")\n",
    "        else:\n",
    "            print(\"  ❌ UnifiedDataLoader クラスが見つかりません\")\n",
    "            \n",
    "    except Exception as direct_error:\n",
    "        print(f\"  ❌ 直接読み込みエラー: {direct_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前学習済みモデルの確認\n",
    "pretrained_path = 'models/saved/best_model.pth'\n",
    "\n",
    "if os.path.exists(pretrained_path):\n",
    "    print(f\"事前学習済みモデルが見つかりました: {pretrained_path}\")\n",
    "    \n",
    "    # モデル情報確認\n",
    "    checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "    if 'metadata' in checkpoint:\n",
    "        metadata = checkpoint['metadata']\n",
    "        print(f\"前回の学習エポック: {metadata.get('epoch', 'Unknown')}\")\n",
    "        print(f\"検証損失: {metadata.get('val_loss', 'Unknown')}\")\n",
    "        print(f\"精度: {metadata.get('accuracy', 'Unknown')}\")\n",
    "        \n",
    "    use_pretrained = True\n",
    "else:\n",
    "    print(\"事前学習済みモデルが見つかりません。新規学習を開始します。\")\n",
    "    pretrained_path = None\n",
    "    use_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統合学習開始\n",
    "print(\"=\" * 60)\n",
    "print(\"🌍 UNIFIED MULTI-LEAGUE TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 統合データローダー初期化\n",
    "data_loader = UnifiedDataLoader(TRAINING_CONFIG)\n",
    "\n",
    "# 事前学習済みエンコーダー読み込み（あれば）\n",
    "encoder_path = DRIVE_CONFIG['encoder_save_path']\n",
    "if os.path.exists(encoder_path):\n",
    "    data_loader.load_team_encoder(encoder_path)\n",
    "    print(f\"✅ 既存のチームエンコーダーを読み込み: {len(data_loader.team_encoder)}チーム\")\n",
    "\n",
    "# 統合データセット作成\n",
    "print(f\"📊 Google Driveからデータ読み込み: {DRIVE_CONFIG['csv_dir']}\")\n",
    "train_dataloader = data_loader.load_from_drive(DRIVE_CONFIG['csv_dir'])\n",
    "\n",
    "# チームエンコーダー保存\n",
    "data_loader.save_team_encoder(DRIVE_CONFIG['encoder_save_path'])\n",
    "print(f\"💾 チームエンコーダー保存: {DRIVE_CONFIG['encoder_save_path']}\")\n",
    "\n",
    "# トレーナー初期化\n",
    "trainer = FootballTrainer(TRAINING_CONFIG)\n",
    "\n",
    "# 事前学習済みモデル読み込み（あれば）\n",
    "pretrained_model_path = os.path.join(DRIVE_CONFIG['model_save_dir'], 'best_model.pth')\n",
    "if os.path.exists(pretrained_model_path) and use_pretrained:\n",
    "    trainer.initialize_model(pretrained_model_path)\n",
    "    print(f\"🔄 継続学習モード: {pretrained_model_path}\")\n",
    "else:\n",
    "    trainer.initialize_model(None)\n",
    "    print(\"🆕 新規学習モード\")\n",
    "\n",
    "# 学習実行\n",
    "print(\"\\n🚀 統合学習開始...\")\n",
    "trainer.train_with_unified_data(\n",
    "    train_dataloader=train_dataloader,\n",
    "    validation_split=0.2,\n",
    "    save_path=DRIVE_CONFIG['model_save_dir'],\n",
    "    checkpoint_interval=25\n",
    ")\n",
    "\n",
    "print(\"✅ 統合学習完了！\")\n",
    "print(\"🏆 全リーグのパターンを学習したモデルが完成しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeee6c",
   "metadata": {},
   "source": [
    "## 📈 モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習履歴の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 損失\n",
    "    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['epoch'], history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # ゴール予測損失\n",
    "    axes[0, 1].plot(history['epoch'], history['goal_loss'], label='Goal Loss', color='orange')\n",
    "    axes[0, 1].set_title('Goal Prediction Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('MSE Loss')\n",
    "    \n",
    "    # 結果予測損失\n",
    "    axes[1, 0].plot(history['epoch'], history['result_loss'], label='Result Loss', color='green')\n",
    "    axes[1, 0].set_title('Result Prediction Loss')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('CrossEntropy Loss')\n",
    "    \n",
    "    # 精度\n",
    "    axes[1, 1].plot(history['epoch'], history['accuracy'], label='Accuracy', color='red')\n",
    "    axes[1, 1].set_title('Classification Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 学習履歴プロット\n",
    "if trainer.train_history['epoch']:\n",
    "    plot_training_history(trainer.train_history)\n",
    "else:\n",
    "    print(\"学習履歴が見つかりません\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルテスト予測\n",
    "def test_model_prediction():\n",
    "    # 最新モデル読み込み\n",
    "    model = FootballMatchPredictor.load_model(\n",
    "        'models/saved/best_model.pth', \n",
    "        device=TRAINING_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # チームエンコーダー読み込み\n",
    "    import json\n",
    "    with open('models/saved/team_encoder.json', 'r', encoding='utf-8') as f:\n",
    "        team_encoder = json.load(f)\n",
    "    \n",
    "    # サンプル予測\n",
    "    sample_matches = [\n",
    "        {\n",
    "            'home_team': 'Manchester City',\n",
    "            'away_team': 'Liverpool',\n",
    "            'features': np.array([2.8, 2.7, 2.9, 2.6, 2.2, 2.0, 1.0, 1.1, 0.5, 0.3, 0.1])\n",
    "        },\n",
    "        {\n",
    "            'home_team': 'Arsenal', \n",
    "            'away_team': 'Chelsea',\n",
    "            'features': np.array([2.1, 2.0, 2.2, 1.9, 1.8, 1.7, 1.2, 1.3, 0.6, 0.3, -0.1])\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"🔮 サンプル予測結果:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for match in sample_matches:\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        \n",
    "        if home_team in team_encoder and away_team in team_encoder:\n",
    "            home_id = team_encoder[home_team]\n",
    "            away_id = team_encoder[away_team]\n",
    "            \n",
    "            prediction = model.predict_match(home_id, away_id, match['features'])\n",
    "            \n",
    "            print(f\"\\n{home_team} vs {away_team}\")\n",
    "            print(f\"予測スコア: {prediction['home_goals']:.1f} - {prediction['away_goals']:.1f}\")\n",
    "            print(f\"勝利確率: ホーム {prediction['home_win_prob']:.1%}, \"\n",
    "                  f\"ドロー {prediction['draw_prob']:.1%}, \"\n",
    "                  f\"アウェイ {prediction['away_win_prob']:.1%}\")\n",
    "            print(f\"予測結果: {prediction['predicted_result']}\")\n",
    "        else:\n",
    "            print(f\"チーム {home_team} または {away_team} がエンコーダーに見つかりません\")\n",
    "\n",
    "test_model_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e64c9",
   "metadata": {},
   "source": [
    "## 💾 モデル保存とダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終モデルを日付付きで保存\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_model_path = f'models/saved/football_predictor_{timestamp}.pth'\n",
    "\n",
    "# 最新のベストモデルをコピー\n",
    "!cp models/saved/best_model.pth \"{final_model_path}\"\n",
    "\n",
    "print(f\"最終モデル保存: {final_model_path}\")\n",
    "\n",
    "# モデルファイル一覧\n",
    "print(\"\\n保存済みモデル:\")\n",
    "!ls -lh models/saved/*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルとエンコーダーをダウンロード\n",
    "from google.colab import files\n",
    "\n",
    "# ダウンロード対象ファイル\n",
    "download_files = [\n",
    "    'models/saved/best_model.pth',\n",
    "    'models/saved/team_encoder.json',\n",
    "    final_model_path\n",
    "]\n",
    "\n",
    "print(\"ダウンロード開始...\")\n",
    "for file_path in download_files:\n",
    "    if os.path.exists(file_path):\n",
    "        files.download(file_path)\n",
    "        print(f\"✅ {file_path} ダウンロード完了\")\n",
    "    else:\n",
    "        print(f\"❌ {file_path} が見つかりません\")\n",
    "\n",
    "print(\"\\n📁 ダウンロードしたファイルをローカルの models/saved/ ディレクトリに配置してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b612f",
   "metadata": {},
   "source": [
    "## 🎯 次のステップ\n",
    "\n",
    "1. **ローカル環境での予測**: ダウンロードしたモデルをローカル環境で使用\n",
    "2. **新データでファインチューニング**: 新しいリーグデータが追加されたら継続学習\n",
    "3. **予測精度の評価**: 実際の試合結果と比較して精度を検証\n",
    "4. **自動化**: 定期的な学習とモデル更新の自動化\n",
    "\n",
    "### 継続学習の実行方法\n",
    "```python\n",
    "# 新しいデータを追加後、このノートブックを再実行\n",
    "# 事前学習済みモデルが自動的に読み込まれ、ファインチューニングが実行されます\n",
    "```\n",
    "\n",
    "### ローカルでの使用方法\n",
    "```python\n",
    "from src.prediction.predict_matches import predict_weekly_matches\n",
    "\n",
    "# 週次予測の実行\n",
    "predictions = predict_weekly_matches('data/fixtures/current_season.csv')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
