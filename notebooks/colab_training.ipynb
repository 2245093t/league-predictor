{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2868b398",
   "metadata": {},
   "source": [
    "# âš½ Football League Predictor - Training Notebook\n",
    "\n",
    "Google Colab GPUç’°å¢ƒã§ã®æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "## ğŸ¯ ç›®çš„\n",
    "- è¤‡æ•°ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ã§çµ±åˆå­¦ç¿’\n",
    "- ã‚ªãƒƒã‚ºã«ä¾å­˜ã—ãªã„PPGãƒ»xGãƒ™ãƒ¼ã‚¹ã®äºˆæ¸¬\n",
    "- ç¶™ç¶šå­¦ç¿’ãƒ»ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾å¿œ\n",
    "- PyTorchãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808a812",
   "metadata": {},
   "source": [
    "## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install pytorch-lightning\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "!pip install pyyaml hydra-core\n",
    "\n",
    "# GPUç¢ºèª\n",
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveãƒã‚¦ãƒ³ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ï¼‰\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šï¼ˆçµ±ä¸€ï¼‰\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/league-predictor'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"ğŸ“ Google Driveãƒã‚¦ãƒ³ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ac675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHubãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³ï¼ˆåˆå›ã®ã¿ï¼‰\n",
    "if not os.path.exists('league-predictor'):\n",
    "    !git clone https://github.com/2245093t/league-predictor.git\n",
    "    print(\"âœ… GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã—ãŸ\")\n",
    "else:\n",
    "    print(\"âœ… GitHubãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™\")\n",
    "    \n",
    "# league-predictorãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•\n",
    "os.chdir('league-predictor')\n",
    "print(f\"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n",
    "\n",
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª\n",
    "print(\"\\nğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\nğŸ“ srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹:\")\n",
    "if os.path.exists('src'):\n",
    "    !ls -la src/\n",
    "    print(\"\\nğŸ“ src/training ã®å†…å®¹:\")\n",
    "    if os.path.exists('src/training'):\n",
    "        !ls -la src/training/\n",
    "else:\n",
    "    print(\"âŒ srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901ff0a",
   "metadata": {},
   "source": [
    "## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆGoogle Driveçµ±åˆç®¡ç†ï¼‰\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
    "CSV_DIR = \"/content/drive/MyDrive/league-predictor/stats-csv\"\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "# æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª\n",
    "existing_files = glob.glob(os.path.join(CSV_DIR, \"*.csv\"))\n",
    "print(f\"æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«: {len(existing_files)}å€‹\")\n",
    "for file in existing_files:\n",
    "    filename = os.path.basename(file)\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"  {filename}: {len(df)}è©¦åˆ\")\n",
    "\n",
    "# æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "print(\"\\næ–°ã—ã„ãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n",
    "print(\"ï¼ˆè¤‡æ•°ã®ãƒªãƒ¼ã‚°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€åº¦ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ï¼‰\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•\n",
    "for filename in uploaded.keys():\n",
    "    destination = os.path.join(CSV_DIR, filename)\n",
    "    !mv \"{filename}\" \"{destination}\"\n",
    "    print(f\"  {filename} â†’ {destination}\")\n",
    "        \n",
    "print(f\"\\nãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {CSV_DIR}\")\n",
    "print(\"å…¨ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒçµ±åˆã•ã‚Œã€å¯¾ç­‰ã«æ‰±ã‚ã‚Œã¾ã™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆãƒ‡ãƒ¼ã‚¿æ¦‚è¦ç¢ºèª\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# srcãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’è¿½åŠ \n",
    "sys.path.append('src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/src')\n",
    "\n",
    "from training.data_loader import UnifiedDataLoader\n",
    "\n",
    "def analyze_unified_data():\n",
    "    \"\"\"çµ±åˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’åˆ†æ\"\"\"\n",
    "    \n",
    "    config = {'batch_size': 64, 'feature_dim': 11}\n",
    "    loader = UnifiedDataLoader(config)\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±å–å¾—\n",
    "    stats = loader.get_league_statistics(CSV_DIR)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸŒ UNIFIED LEAGUE DATA ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"ğŸ“Š å…¨ä½“çµ±è¨ˆ:\")\n",
    "    print(f\"  ç·è©¦åˆæ•°: {stats['total_matches']:,}\")\n",
    "    print(f\"  ç·ãƒãƒ¼ãƒ æ•°: {stats['total_teams']:,}\")\n",
    "    \n",
    "    print(f\"\\nğŸ† ãƒªãƒ¼ã‚°åˆ¥åˆ†å¸ƒ:\")\n",
    "    for league, count in stats['league_distribution'].items():\n",
    "        percentage = (count / stats['total_matches']) * 100\n",
    "        print(f\"  {league}: {count:,}è©¦åˆ ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nâš½ ãƒªãƒ¼ã‚°åˆ¥ãƒãƒ¼ãƒ æ•°:\")\n",
    "    for league, count in stats['teams_per_league'].items():\n",
    "        print(f\"  {league}: {count}ãƒãƒ¼ãƒ \")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "    csv_files = glob.glob(os.path.join(CSV_DIR, \"*.csv\"))\n",
    "    print(f\"\\nğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°:\")\n",
    "    \n",
    "    total_size = 0\n",
    "    for csv_file in csv_files:\n",
    "        filename = os.path.basename(csv_file)\n",
    "        file_size = os.path.getsize(csv_file) / (1024 * 1024)  # MB\n",
    "        total_size += file_size\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"  {filename}\")\n",
    "        print(f\"    ã‚µã‚¤ã‚º: {file_size:.1f}MB\")\n",
    "        print(f\"    è©¦åˆæ•°: {len(df):,}\")\n",
    "        print(f\"    ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size:.1f}MB\")\n",
    "    print(\"\\nâœ… å…¨ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒçµ±åˆæº–å‚™å®Œäº†ï¼\")\n",
    "\n",
    "analyze_unified_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51b542",
   "metadata": {},
   "source": [
    "## âš™ï¸ å­¦ç¿’è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea673e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆå­¦ç¿’è¨­å®š\n",
    "TRAINING_CONFIG = {\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
    "    'num_teams': 500,        # å¤šãƒªãƒ¼ã‚°çµ±åˆã®ãŸã‚å¤§å¹…å¢—åŠ \n",
    "    'embedding_dim': 64,     # ãƒãƒ¼ãƒ åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒå¢—åŠ \n",
    "    'hidden_dim': 512,       # éš ã‚Œå±¤æ¬¡å…ƒå¢—åŠ \n",
    "    'dropout': 0.3,          # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡\n",
    "    \n",
    "    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 128,       # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ãƒãƒƒãƒã‚µã‚¤ã‚ºå¢—åŠ \n",
    "    'epochs': 150,           # ã‚¨ãƒãƒƒã‚¯æ•°èª¿æ•´\n",
    "    \n",
    "    # æå¤±é–¢æ•°é‡ã¿\n",
    "    'goal_loss_weight': 1.0,\n",
    "    'result_loss_weight': 2.0,\n",
    "    \n",
    "    # ãƒ‡ãƒã‚¤ã‚¹\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Google Driveè¨­å®š\n",
    "DRIVE_CONFIG = {\n",
    "    'csv_dir': CSV_DIR,\n",
    "    'model_save_dir': '/content/drive/MyDrive/league-predictor/models',\n",
    "    'encoder_save_path': '/content/drive/MyDrive/league-predictor/models/team_encoder.json'\n",
    "}\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "os.makedirs(DRIVE_CONFIG['model_save_dir'], exist_ok=True)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“‹ çµ±åˆå­¦ç¿’è¨­å®š\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“ CSVãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DRIVE_CONFIG['csv_dir']}\")\n",
    "print(f\"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DRIVE_CONFIG['model_save_dir']}\")\n",
    "print(f\"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {TRAINING_CONFIG['device']}\")\n",
    "print(f\"ğŸ§  æœ€å¤§ãƒãƒ¼ãƒ æ•°: {TRAINING_CONFIG['num_teams']}\")\n",
    "print(f\"ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"ğŸ”„ ã‚¨ãƒãƒƒã‚¯æ•°: {TRAINING_CONFIG['epochs']}\")\n",
    "print()\n",
    "print(\"âœ… å…¨ãƒªãƒ¼ã‚°ãŒå¯¾ç­‰ã«æ‰±ã‚ã‚Œã‚‹çµ±åˆå­¦ç¿’ã®æº–å‚™å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20a1ad",
   "metadata": {},
   "source": [
    "## ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆå­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# srcãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’è¿½åŠ ï¼ˆè¤‡æ•°ã®å¯èƒ½æ€§ã«å¯¾å¿œï¼‰\n",
    "sys.path.append('src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/src')\n",
    "sys.path.append('/content/drive/MyDrive/league-predictor/league-predictor/src')\n",
    "\n",
    "# ç¾åœ¨ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python path: {sys.path[-3:]}\")\n",
    "\n",
    "try:\n",
    "    # æ­£ã—ã„ã‚¯ãƒ©ã‚¹åã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "    from training.data_loader import UnifiedDataLoader\n",
    "    from training.train_model import FootballTrainer\n",
    "    from training.model_architecture import FootballMatchPredictor\n",
    "    \n",
    "    print(\"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n",
    "    print(\"ğŸŒ å…¨ãƒªãƒ¼ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãŒå¯¾ç­‰ã«æ‰±ã‚ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã™\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"ğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¾ã™:\")\n",
    "    \n",
    "    # srcãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹ç¢ºèª\n",
    "    if os.path.exists('src'):\n",
    "        print(\"src/ ãƒ•ã‚©ãƒ«ãƒ€ã®å†…å®¹:\")\n",
    "        for root, dirs, files in os.walk('src'):\n",
    "            level = root.replace('src', '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for file in files:\n",
    "                if file.endswith('.py'):\n",
    "                    print(f\"{subindent}{file}\")\n",
    "    else:\n",
    "        print(\"src/ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    # å…·ä½“çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ç¢ºèª\n",
    "    data_loader_path = 'src/training/data_loader.py'\n",
    "    if os.path.exists(data_loader_path):\n",
    "        print(f\"\\nğŸ“„ {data_loader_path} ã®å†…å®¹ã‚’ç¢ºèª:\")\n",
    "        with open(data_loader_path, 'r') as f:\n",
    "            lines = f.readlines()[:20]  # æœ€åˆã®20è¡Œã‚’è¡¨ç¤º\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                if 'class' in line or 'def' in line:\n",
    "                    print(f\"  {i}: {line.strip()}\")\n",
    "    \n",
    "    # ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ\n",
    "    print(\"\\nğŸ”§ ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ:\")\n",
    "    try:\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\"data_loader\", data_loader_path)\n",
    "        data_loader_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(data_loader_module)\n",
    "        \n",
    "        # åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚’ç¢ºèª\n",
    "        classes = [name for name in dir(data_loader_module) if name[0].isupper()]\n",
    "        print(f\"  åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹: {classes}\")\n",
    "        \n",
    "        # UnifiedDataLoaderã‚¯ãƒ©ã‚¹ã‚’å–å¾—\n",
    "        if hasattr(data_loader_module, 'UnifiedDataLoader'):\n",
    "            UnifiedDataLoader = getattr(data_loader_module, 'UnifiedDataLoader')\n",
    "            print(\"  âœ… UnifiedDataLoader ã‚’ç›´æ¥èª­ã¿è¾¼ã¿æˆåŠŸ\")\n",
    "        else:\n",
    "            print(\"  âŒ UnifiedDataLoader ã‚¯ãƒ©ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "            \n",
    "    except Exception as direct_error:\n",
    "        print(f\"  âŒ ç›´æ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {direct_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª\n",
    "pretrained_path = 'models/saved/best_model.pth'\n",
    "\n",
    "if os.path.exists(pretrained_path):\n",
    "    print(f\"äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {pretrained_path}\")\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ç¢ºèª\n",
    "    checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "    if 'metadata' in checkpoint:\n",
    "        metadata = checkpoint['metadata']\n",
    "        print(f\"å‰å›ã®å­¦ç¿’ã‚¨ãƒãƒƒã‚¯: {metadata.get('epoch', 'Unknown')}\")\n",
    "        print(f\"æ¤œè¨¼æå¤±: {metadata.get('val_loss', 'Unknown')}\")\n",
    "        print(f\"ç²¾åº¦: {metadata.get('accuracy', 'Unknown')}\")\n",
    "        \n",
    "    use_pretrained = True\n",
    "else:\n",
    "    print(\"äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚\")\n",
    "    pretrained_path = None\n",
    "    use_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±åˆå­¦ç¿’é–‹å§‹\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸŒ UNIFIED MULTI-LEAGUE TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–\n",
    "data_loader = UnifiedDataLoader(TRAINING_CONFIG)\n",
    "\n",
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰\n",
    "encoder_path = DRIVE_CONFIG['encoder_save_path']\n",
    "if os.path.exists(encoder_path):\n",
    "    data_loader.load_team_encoder(encoder_path)\n",
    "    print(f\"âœ… æ—¢å­˜ã®ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’èª­ã¿è¾¼ã¿: {len(data_loader.team_encoder)}ãƒãƒ¼ãƒ \")\n",
    "\n",
    "# çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "print(f\"ğŸ“Š Google Driveã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {DRIVE_CONFIG['csv_dir']}\")\n",
    "train_dataloader = data_loader.load_from_drive(DRIVE_CONFIG['csv_dir'])\n",
    "\n",
    "# ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ä¿å­˜\n",
    "data_loader.save_team_encoder(DRIVE_CONFIG['encoder_save_path'])\n",
    "print(f\"ğŸ’¾ ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ä¿å­˜: {DRIVE_CONFIG['encoder_save_path']}\")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–\n",
    "trainer = FootballTrainer(TRAINING_CONFIG)\n",
    "\n",
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰\n",
    "pretrained_model_path = os.path.join(DRIVE_CONFIG['model_save_dir'], 'best_model.pth')\n",
    "if os.path.exists(pretrained_model_path) and use_pretrained:\n",
    "    trainer.initialize_model(pretrained_model_path)\n",
    "    print(f\"ğŸ”„ ç¶™ç¶šå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰: {pretrained_model_path}\")\n",
    "else:\n",
    "    trainer.initialize_model(None)\n",
    "    print(\"ğŸ†• æ–°è¦å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰\")\n",
    "\n",
    "# å­¦ç¿’å®Ÿè¡Œ\n",
    "print(\"\\nğŸš€ çµ±åˆå­¦ç¿’é–‹å§‹...\")\n",
    "trainer.train_with_unified_data(\n",
    "    train_dataloader=train_dataloader,\n",
    "    validation_split=0.2,\n",
    "    save_path=DRIVE_CONFIG['model_save_dir'],\n",
    "    checkpoint_interval=25\n",
    ")\n",
    "\n",
    "print(\"âœ… çµ±åˆå­¦ç¿’å®Œäº†ï¼\")\n",
    "print(\"ğŸ† å…¨ãƒªãƒ¼ã‚°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeee6c",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # æå¤±\n",
    "    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['epoch'], history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # ã‚´ãƒ¼ãƒ«äºˆæ¸¬æå¤±\n",
    "    axes[0, 1].plot(history['epoch'], history['goal_loss'], label='Goal Loss', color='orange')\n",
    "    axes[0, 1].set_title('Goal Prediction Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('MSE Loss')\n",
    "    \n",
    "    # çµæœäºˆæ¸¬æå¤±\n",
    "    axes[1, 0].plot(history['epoch'], history['result_loss'], label='Result Loss', color='green')\n",
    "    axes[1, 0].set_title('Result Prediction Loss')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('CrossEntropy Loss')\n",
    "    \n",
    "    # ç²¾åº¦\n",
    "    axes[1, 1].plot(history['epoch'], history['accuracy'], label='Accuracy', color='red')\n",
    "    axes[1, 1].set_title('Classification Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# å­¦ç¿’å±¥æ­´ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "if trainer.train_history['epoch']:\n",
    "    plot_training_history(trainer.train_history)\n",
    "else:\n",
    "    print(\"å­¦ç¿’å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆäºˆæ¸¬\n",
    "def test_model_prediction():\n",
    "    # æœ€æ–°ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿\n",
    "    model = FootballMatchPredictor.load_model(\n",
    "        'models/saved/best_model.pth', \n",
    "        device=TRAINING_CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    # ãƒãƒ¼ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿\n",
    "    import json\n",
    "    with open('models/saved/team_encoder.json', 'r', encoding='utf-8') as f:\n",
    "        team_encoder = json.load(f)\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬\n",
    "    sample_matches = [\n",
    "        {\n",
    "            'home_team': 'Manchester City',\n",
    "            'away_team': 'Liverpool',\n",
    "            'features': np.array([2.8, 2.7, 2.9, 2.6, 2.2, 2.0, 1.0, 1.1, 0.5, 0.3, 0.1])\n",
    "        },\n",
    "        {\n",
    "            'home_team': 'Arsenal', \n",
    "            'away_team': 'Chelsea',\n",
    "            'features': np.array([2.1, 2.0, 2.2, 1.9, 1.8, 1.7, 1.2, 1.3, 0.6, 0.3, -0.1])\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”® ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬çµæœ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for match in sample_matches:\n",
    "        home_team = match['home_team']\n",
    "        away_team = match['away_team']\n",
    "        \n",
    "        if home_team in team_encoder and away_team in team_encoder:\n",
    "            home_id = team_encoder[home_team]\n",
    "            away_id = team_encoder[away_team]\n",
    "            \n",
    "            prediction = model.predict_match(home_id, away_id, match['features'])\n",
    "            \n",
    "            print(f\"\\n{home_team} vs {away_team}\")\n",
    "            print(f\"äºˆæ¸¬ã‚¹ã‚³ã‚¢: {prediction['home_goals']:.1f} - {prediction['away_goals']:.1f}\")\n",
    "            print(f\"å‹åˆ©ç¢ºç‡: ãƒ›ãƒ¼ãƒ  {prediction['home_win_prob']:.1%}, \"\n",
    "                  f\"ãƒ‰ãƒ­ãƒ¼ {prediction['draw_prob']:.1%}, \"\n",
    "                  f\"ã‚¢ã‚¦ã‚§ã‚¤ {prediction['away_win_prob']:.1%}\")\n",
    "            print(f\"äºˆæ¸¬çµæœ: {prediction['predicted_result']}\")\n",
    "        else:\n",
    "            print(f\"ãƒãƒ¼ãƒ  {home_team} ã¾ãŸã¯ {away_team} ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "test_model_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e64c9",
   "metadata": {},
   "source": [
    "## ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’æ—¥ä»˜ä»˜ãã§ä¿å­˜\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_model_path = f'models/saved/football_predictor_{timestamp}.pth'\n",
    "\n",
    "# æœ€æ–°ã®ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
    "!cp models/saved/best_model.pth \"{final_model_path}\"\n",
    "\n",
    "print(f\"æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {final_model_path}\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n",
    "print(\"\\nä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«:\")\n",
    "!ls -lh models/saved/*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "from google.colab import files\n",
    "\n",
    "# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "download_files = [\n",
    "    'models/saved/best_model.pth',\n",
    "    'models/saved/team_encoder.json',\n",
    "    final_model_path\n",
    "]\n",
    "\n",
    "print(\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹...\")\n",
    "for file_path in download_files:\n",
    "    if os.path.exists(file_path):\n",
    "        files.download(file_path)\n",
    "        print(f\"âœ… {file_path} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "    else:\n",
    "        print(f\"âŒ {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "print(\"\\nğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã® models/saved/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b612f",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "1. **ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®äºˆæ¸¬**: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ä½¿ç”¨\n",
    "2. **æ–°ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: æ–°ã—ã„ãƒªãƒ¼ã‚°ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚ŒãŸã‚‰ç¶™ç¶šå­¦ç¿’\n",
    "3. **äºˆæ¸¬ç²¾åº¦ã®è©•ä¾¡**: å®Ÿéš›ã®è©¦åˆçµæœã¨æ¯”è¼ƒã—ã¦ç²¾åº¦ã‚’æ¤œè¨¼\n",
    "4. **è‡ªå‹•åŒ–**: å®šæœŸçš„ãªå­¦ç¿’ã¨ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã®è‡ªå‹•åŒ–\n",
    "\n",
    "### ç¶™ç¶šå­¦ç¿’ã®å®Ÿè¡Œæ–¹æ³•\n",
    "```python\n",
    "# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ å¾Œã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å†å®Ÿè¡Œ\n",
    "# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œã•ã‚Œã¾ã™\n",
    "```\n",
    "\n",
    "### ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ä½¿ç”¨æ–¹æ³•\n",
    "```python\n",
    "from src.prediction.predict_matches import predict_weekly_matches\n",
    "\n",
    "# é€±æ¬¡äºˆæ¸¬ã®å®Ÿè¡Œ\n",
    "predictions = predict_weekly_matches('data/fixtures/current_season.csv')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
